{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# TOPIC MODEL"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Imports"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import warnings\r\n",
    "warnings.filterwarnings(action='ignore', category=UserWarning, module='gensim')\r\n",
    "import gensim\r\n",
    "from gensim.utils import simple_preprocess # converts a document into a list of tokens\r\n",
    "from gensim.parsing.preprocessing import STOPWORDS # list of stop words\r\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\r\n",
    "from nltk.stem.porter import *\r\n",
    "import numpy as np\r\n",
    "import nltk \r\n",
    "import pandas as pd\r\n",
    "\r\n",
    "nltk.download('wordnet')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Clearing and getting data ready"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# load the data\r\n",
    "\r\n",
    "data = pd.read_csv('india-news-headlines.csv', error_bad_lines=False)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "# Retrieving only the Headlines text column for the data\r\n",
    "\r\n",
    "data_text = data[['headline_text']]\r\n",
    "\r\n",
    "data_text['index'] = data_text.index\r\n",
    "\r\n",
    "data_text.head(10)\r\n",
    "\r\n",
    "documents = data_text"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "print(len(documents))\r\n",
    "print(documents[:10])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "3424067\n",
      "                                       headline_text  index\n",
      "0  Status quo will not be disturbed at Ayodhya; s...      0\n",
      "1                Fissures in Hurriyat over Pak visit      1\n",
      "2              America's unwanted heading for India?      2\n",
      "3                 For bigwigs; it is destination Goa      3\n",
      "4               Extra buses to clear tourist traffic      4\n",
      "5        Dilute the power of transfers; says Riberio      5\n",
      "6                  Focus shifts to teaching of Hindi      6\n",
      "7               IT will become compulsory in schools      7\n",
      "8      Move to stop freedom fighters' pension flayed      8\n",
      "9  Gilani claims he applied for passport 2 years ago      9\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Before we continue we need to handle few things:\r\n",
    "\r\n",
    "* Tokenization: Splitting documents into sentences and words.\r\n",
    "* Removing stop words like (the, a, an, in)\r\n",
    "* Stemming: reducing words to their root form"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "# setting up the stemmer\r\n",
    "\r\n",
    "stemmer = SnowballStemmer(\"english\")\r\n",
    "\r\n",
    "\r\n",
    "# returns the root value of the word\r\n",
    "\r\n",
    "def lemmatize_stemming(word):    \r\n",
    "    return stemmer.stem(WordNetLemmatizer().lemmatize(word,pos='v'))\r\n",
    "\r\n",
    "# pull out the stopwords from the sentences\r\n",
    "\r\n",
    "def preprocess(text):\r\n",
    "    result = []\r\n",
    "    for token in simple_preprocess(text):\r\n",
    "\r\n",
    "        if (token not in STOPWORDS) and (len(token) > 3):\r\n",
    "\r\n",
    "            result.append(lemmatize_stemming(token))\r\n",
    "\r\n",
    "    return result\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Sample demonstration of the above functions"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "source": [
    "doc_sample = documents[documents['index'] == 6].values[0][0]\r\n",
    "print(\"RAW:\\n\",doc_sample)\r\n",
    "\r\n",
    "print('\\n\\noriginal document: ')\r\n",
    "words = []\r\n",
    "for word in doc_sample.split(' '): words.append(word)\r\n",
    "print(words)\r\n",
    "print(\"\\n\\nTokenized and lemmatized doc: \")\r\n",
    "print(preprocess(doc_sample))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "RAW:\n",
      " Focus shifts to teaching of Hindi\n",
      "\n",
      "\n",
      "original document: \n",
      "['Focus', 'shifts', 'to', 'teaching', 'of', 'Hindi']\n",
      "\n",
      "\n",
      "Tokenized and lemmatized doc: \n",
      "['focus', 'shift', 'teach', 'hindi']\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Apply process to the every sentence"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "source": [
    "processed_docs = documents['headline_text'].map(preprocess)\r\n",
    "processed_docs"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0                   [status, disturb, ayodhya, say, vajpaye]\n",
       "1                                  [fissur, hurriyat, visit]\n",
       "2                             [america, unwant, head, india]\n",
       "3                                           [bigwig, destin]\n",
       "4                      [extra, bus, clear, tourist, traffic]\n",
       "5                     [dilut, power, transfer, say, riberio]\n",
       "6                               [focus, shift, teach, hindi]\n",
       "7                                       [compulsori, school]\n",
       "8                    [stop, freedom, fighter, pension, flay]\n",
       "9                     [gilani, claim, appli, passport, year]\n",
       "10                                  [parivar, dismiss, warn]\n",
       "11                             [india, exchang, list, plant]\n",
       "12                             [qureshi, return, help, govt]\n",
       "13                              [tacit, messag, tampl, hold]\n",
       "14                             [text, prime, minist, articl]\n",
       "15                                   [focus, violenc, women]\n",
       "16                                    [realiti, focus, aiim]\n",
       "17                            [jaitley, firm, legal, reform]\n",
       "18                              [hoshangabad, farmer, water]\n",
       "19                        [jump, rail, track, convers, issu]\n",
       "20                            [america, unwant, head, india]\n",
       "21                                   [state, court, krishna]\n",
       "22                                     [offici, sue, briber]\n",
       "23               [park, turn, templ, compound, resid, watch]\n",
       "24               [move, afoot, evict, squatter, urban, dist]\n",
       "25                          [mafia, call, shot, gandhinagar]\n",
       "26                  [status, disturb, ayodhya, say, vajpaye]\n",
       "27                                 [fissur, hurriyat, visit]\n",
       "28                            [america, unwant, head, india]\n",
       "29                                          [bigwig, destin]\n",
       "                                 ...                        \n",
       "3424037    [karnataka, gram, panchayat, elect, candid, ba...\n",
       "3424038                  [local, train, servic, resum, year]\n",
       "3424039    [bengaluru, addit, involv, safe, citi, project...\n",
       "3424040    [rais, complaint, tender, bharat, electron, li...\n",
       "3424041            [peopl, rescu, traffic, cop, irat, bunch]\n",
       "3424042      [govt, extend, deadlin, fastag, till, februari]\n",
       "3424043       [day, chang, world, covid, slip, china, grasp]\n",
       "3424044    [bengaluru, safe, citi, project, seek, probe, ...\n",
       "3424045                            [free, leav, turn, right]\n",
       "3424046    [mumbai, year, revel, stay, indoor, tonight, h...\n",
       "3424047                                     [food, deliveri]\n",
       "3424048                     [cop, watch, celebr, year, home]\n",
       "3424049    [bengaluru, kill, retir, banker, properti, aff...\n",
       "3424050    [today, station, covid, marshal, gateway, mumb...\n",
       "3424051    [coupl, shoot, dead, rohtak, woman, uncl, rela...\n",
       "3424052                         [rule, angl, sushant, death]\n",
       "3424053    [ajinkya, rahan, show, mental, strength, tour,...\n",
       "3424054    [turn, telangana, adopt, ayushman, bharat, sch...\n",
       "3424055         [govern, extend, deadlin, file, return, day]\n",
       "3424056     [hold, bengaluru, tri, swap, note, worth, crore]\n",
       "3424057           [nris, reach, singhu, offer, help, farmer]\n",
       "3424058    [navjot, singh, sidhu, tweet, apolog, say, wea...\n",
       "3424059                [azim, premji, organis, misus, cheat]\n",
       "3424060                         [govt, probe, offici, agenc]\n",
       "3424061     [peddler, nab, ganja, seiz, anantapur, district]\n",
       "3424062    [covid, despit, case, rajasthan, state, report...\n",
       "3424063    [covid, despit, case, rajasthan, state, report...\n",
       "3424064    [covid, despit, case, rajasthan, state, report...\n",
       "3424065      [govt, extend, deadlin, fastag, till, februari]\n",
       "3424066            [celeb, plan, parti, safe, respons, year]\n",
       "Name: headline_text, Length: 3424067, dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 37
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "source": [
    "dictionary = gensim.corpora.Dictionary(processed_docs)\r\n",
    "count = 0\r\n",
    "for k, v in dictionary.iteritems():\r\n",
    "    print(k,v)\r\n",
    "    count += 1\r\n",
    "    if count > 10:\r\n",
    "        break"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0 ayodhya\n",
      "1 disturb\n",
      "2 say\n",
      "3 status\n",
      "4 vajpaye\n",
      "5 fissur\n",
      "6 hurriyat\n",
      "7 visit\n",
      "8 america\n",
      "9 head\n",
      "10 india\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "source": [
    "# filter words that appear under 15 docs and keep the most 10k frequent ones\r\n",
    "\r\n",
    "dictionary.filter_extremes(no_below=15, no_above=0.5, keep_n=10000)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "source": [
    "#now let see what the doc number 6 looks like\r\n",
    "processed_docs[6]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['focus', 'shift', 'teach', 'hindi']"
      ]
     },
     "metadata": {},
     "execution_count": 45
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "source": [
    "bow_corpus = [dictionary.doc2bow(doc) for doc in processed_docs]\r\n",
    "bow_corpus[10]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[(37, 1), (38, 1), (39, 1)]"
      ]
     },
     "metadata": {},
     "execution_count": 51
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "source": [
    "bow_doc_6 = bow_corpus[6]\r\n",
    "for i in range(len(bow_doc_6)): print(\"Word {} (\\\"{}\\\") appears {} time.\".format(bow_doc_6[i][0],dictionary[bow_doc_6[i][0]], bow_doc_6[i][1]))\r\n",
    "\r\n",
    "print(dictionary[bow_doc_6[3][0]])\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Word 21 (\"focus\") appears 1 time.\n",
      "Word 22 (\"hindi\") appears 1 time.\n",
      "Word 23 (\"shift\") appears 1 time.\n",
      "Word 24 (\"teach\") appears 1 time.\n",
      "teach\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[(21, 1), (22, 1), (23, 1), (24, 1)]"
      ]
     },
     "metadata": {},
     "execution_count": 78
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# We can run the model now"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "source": [
    "lda_model = gensim.models.LdaMulticore(bow_corpus, num_topics=10, id2word=dictionary, passes=2, workers=2)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "source": [
    "for idx, topic in lda_model.print_topics(-1):\r\n",
    "    print(\"Topic: {} \\nWords: {}\".format(idx,topic))\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Topic: 0 \n",
      "Words: 0.028*\"bihar\" + 0.021*\"lakh\" + 0.018*\"bengaluru\" + 0.013*\"hold\" + 0.012*\"seiz\" + 0.011*\"celebr\" + 0.011*\"girl\" + 0.011*\"special\" + 0.011*\"plea\" + 0.010*\"polic\"\n",
      "Topic: 1 \n",
      "Words: 0.026*\"rajasthan\" + 0.025*\"crore\" + 0.023*\"plan\" + 0.021*\"state\" + 0.021*\"help\" + 0.015*\"post\" + 0.014*\"near\" + 0.013*\"record\" + 0.013*\"punjab\" + 0.011*\"bengal\"\n",
      "Topic: 2 \n",
      "Words: 0.037*\"covid\" + 0.025*\"home\" + 0.025*\"hospit\" + 0.024*\"pune\" + 0.021*\"patient\" + 0.021*\"student\" + 0.015*\"onlin\" + 0.015*\"doctor\" + 0.014*\"colleg\" + 0.014*\"univers\"\n",
      "Topic: 3 \n",
      "Words: 0.027*\"india\" + 0.022*\"kolkata\" + 0.022*\"day\" + 0.020*\"hyderabad\" + 0.016*\"open\" + 0.015*\"test\" + 0.015*\"covid\" + 0.012*\"drive\" + 0.012*\"give\" + 0.012*\"come\"\n",
      "Topic: 4 \n",
      "Words: 0.053*\"year\" + 0.027*\"woman\" + 0.027*\"kill\" + 0.022*\"book\" + 0.021*\"mumbai\" + 0.016*\"die\" + 0.015*\"death\" + 0.013*\"life\" + 0.012*\"rain\" + 0.010*\"like\"\n",
      "Topic: 5 \n",
      "Words: 0.021*\"polic\" + 0.018*\"bodi\" + 0.018*\"congress\" + 0.017*\"poll\" + 0.015*\"meet\" + 0.014*\"karnataka\" + 0.013*\"elect\" + 0.013*\"order\" + 0.013*\"ahmedabad\" + 0.012*\"case\"\n",
      "Topic: 6 \n",
      "Words: 0.050*\"case\" + 0.030*\"covid\" + 0.028*\"cop\" + 0.025*\"arrest\" + 0.021*\"hold\" + 0.018*\"posit\" + 0.018*\"telangana\" + 0.017*\"district\" + 0.016*\"test\" + 0.014*\"take\"\n",
      "Topic: 7 \n",
      "Words: 0.038*\"say\" + 0.020*\"tamil\" + 0.019*\"farmer\" + 0.019*\"water\" + 0.019*\"lockdown\" + 0.018*\"nadu\" + 0.018*\"high\" + 0.015*\"protest\" + 0.013*\"chennai\" + 0.012*\"demand\"\n",
      "Topic: 8 \n",
      "Words: 0.022*\"maharashtra\" + 0.022*\"death\" + 0.018*\"worker\" + 0.018*\"get\" + 0.017*\"gujarat\" + 0.016*\"school\" + 0.016*\"famili\" + 0.016*\"tell\" + 0.015*\"project\" + 0.014*\"turn\"\n",
      "Topic: 9 \n",
      "Words: 0.034*\"govern\" + 0.028*\"time\" + 0.026*\"road\" + 0.022*\"start\" + 0.016*\"pradesh\" + 0.015*\"return\" + 0.011*\"khan\" + 0.011*\"join\" + 0.010*\"kumar\" + 0.010*\"trichi\"\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "source": [
    "for index, score in sorted(lda_model[bow_doc_6], key= lambda tup: -1*tup[1]):\r\n",
    "    print(\"\\nScore: {}\\t \\nTopic: {}\".format(score, lda_model.print_topic(index, 5)))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Score: 0.41999998688697815\t \n",
      "Topic: 0.050*\"case\" + 0.030*\"covid\" + 0.028*\"cop\" + 0.025*\"arrest\" + 0.021*\"hold\"\n",
      "\n",
      "Score: 0.2199999988079071\t \n",
      "Topic: 0.053*\"year\" + 0.027*\"woman\" + 0.027*\"kill\" + 0.022*\"book\" + 0.021*\"mumbai\"\n",
      "\n",
      "Score: 0.2199999988079071\t \n",
      "Topic: 0.022*\"maharashtra\" + 0.022*\"death\" + 0.018*\"worker\" + 0.018*\"get\" + 0.017*\"gujarat\"\n",
      "\n",
      "Score: 0.019999999552965164\t \n",
      "Topic: 0.028*\"bihar\" + 0.021*\"lakh\" + 0.018*\"bengaluru\" + 0.013*\"hold\" + 0.012*\"seiz\"\n",
      "\n",
      "Score: 0.019999999552965164\t \n",
      "Topic: 0.026*\"rajasthan\" + 0.025*\"crore\" + 0.023*\"plan\" + 0.021*\"state\" + 0.021*\"help\"\n",
      "\n",
      "Score: 0.019999999552965164\t \n",
      "Topic: 0.037*\"covid\" + 0.025*\"home\" + 0.025*\"hospit\" + 0.024*\"pune\" + 0.021*\"patient\"\n",
      "\n",
      "Score: 0.019999999552965164\t \n",
      "Topic: 0.027*\"india\" + 0.022*\"kolkata\" + 0.022*\"day\" + 0.020*\"hyderabad\" + 0.016*\"open\"\n",
      "\n",
      "Score: 0.019999999552965164\t \n",
      "Topic: 0.021*\"polic\" + 0.018*\"bodi\" + 0.018*\"congress\" + 0.017*\"poll\" + 0.015*\"meet\"\n",
      "\n",
      "Score: 0.019999999552965164\t \n",
      "Topic: 0.038*\"say\" + 0.020*\"tamil\" + 0.019*\"farmer\" + 0.019*\"water\" + 0.019*\"lockdown\"\n",
      "\n",
      "Score: 0.019999999552965164\t \n",
      "Topic: 0.034*\"govern\" + 0.028*\"time\" + 0.026*\"road\" + 0.022*\"start\" + 0.016*\"pradesh\"\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "source": [
    "text1 = \"There is a breaktrough in developing vaccine.\"\r\n",
    "text2 = \"There are changes in policies punishing murderers to prevent violence.\"\r\n",
    "unseen_document = text2\r\n",
    "bow_vector = dictionary.doc2bow(preprocess(unseen_document))\r\n",
    "for index, score in sorted(lda_model[bow_vector], key= lambda tup: -1*tup[1]):\r\n",
    "    print(\"\\nScore: {}\\t \\nTopic: {}\".format(score, lda_model.print_topic(index, 7)))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Score: 0.15714287757873535\t \n",
      "Topic: 0.021*\"polic\" + 0.018*\"bodi\" + 0.018*\"congress\" + 0.017*\"poll\" + 0.015*\"meet\" + 0.014*\"karnataka\" + 0.013*\"elect\"\n",
      "\n",
      "Score: 0.15714286267757416\t \n",
      "Topic: 0.026*\"rajasthan\" + 0.025*\"crore\" + 0.023*\"plan\" + 0.021*\"state\" + 0.021*\"help\" + 0.015*\"post\" + 0.014*\"near\"\n",
      "\n",
      "Score: 0.15714286267757416\t \n",
      "Topic: 0.038*\"say\" + 0.020*\"tamil\" + 0.019*\"farmer\" + 0.019*\"water\" + 0.019*\"lockdown\" + 0.018*\"nadu\" + 0.018*\"high\"\n",
      "\n",
      "Score: 0.15714286267757416\t \n",
      "Topic: 0.022*\"maharashtra\" + 0.022*\"death\" + 0.018*\"worker\" + 0.018*\"get\" + 0.017*\"gujarat\" + 0.016*\"school\" + 0.016*\"famili\"\n",
      "\n",
      "Score: 0.15714284777641296\t \n",
      "Topic: 0.037*\"covid\" + 0.025*\"home\" + 0.025*\"hospit\" + 0.024*\"pune\" + 0.021*\"patient\" + 0.021*\"student\" + 0.015*\"onlin\"\n",
      "\n",
      "Score: 0.1571378856897354\t \n",
      "Topic: 0.050*\"case\" + 0.030*\"covid\" + 0.028*\"cop\" + 0.025*\"arrest\" + 0.021*\"hold\" + 0.018*\"posit\" + 0.018*\"telangana\"\n",
      "\n",
      "Score: 0.014290666207671165\t \n",
      "Topic: 0.053*\"year\" + 0.027*\"woman\" + 0.027*\"kill\" + 0.022*\"book\" + 0.021*\"mumbai\" + 0.016*\"die\" + 0.015*\"death\"\n",
      "\n",
      "Score: 0.014285714365541935\t \n",
      "Topic: 0.028*\"bihar\" + 0.021*\"lakh\" + 0.018*\"bengaluru\" + 0.013*\"hold\" + 0.012*\"seiz\" + 0.011*\"celebr\" + 0.011*\"girl\"\n",
      "\n",
      "Score: 0.014285714365541935\t \n",
      "Topic: 0.027*\"india\" + 0.022*\"kolkata\" + 0.022*\"day\" + 0.020*\"hyderabad\" + 0.016*\"open\" + 0.015*\"test\" + 0.015*\"covid\"\n",
      "\n",
      "Score: 0.014285714365541935\t \n",
      "Topic: 0.034*\"govern\" + 0.028*\"time\" + 0.026*\"road\" + 0.022*\"start\" + 0.016*\"pradesh\" + 0.015*\"return\" + 0.011*\"khan\"\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Comments\r\n",
    "\r\n",
    "As we have clearly seen the topic choice for unseen document \"text2\" and \"text1\" is correctly decided respectively to be the \"polic\" and \"covid\", which indicates that our model works fine. Now we can try to determine the topic of an unseen paragraph to further test our model. \r\n",
    "\r\n",
    "Paragraph:\r\n",
    "\r\n",
    "- \"Government! You can't live with it! You can't live without it! It is the \"common cold\" that everyone dreads. The American Heritage College Dictionary, Third Edition defines government as, \"The exercise of authority in a political unit in order to control and administer public policy.\" Webster's Desk Dictionary of the English Language defines government as, \"The political direction and control exercised over a nation, state, community, etc.\" The common individual might define government as the root of all evil. The thing about government is that no one stops to think about how government came about.\""
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "source": [
    "paragraph1 = \"\"\"\r\n",
    "Government! You can't live with it! You can't live without it! It is the \"common cold\" that everyone dreads. The American Heritage College Dictionary, Third Edition defines government as, \"The exercise of authority in a political unit in order to control and administer public policy.\" Webster's Desk Dictionary of the English Language defines government as, \"The political direction and control exercised over a nation, state, community, etc.\" The common individual might define government as the root of all evil. The thing about government is that no one stops to think about how government came about.\r\n",
    "Government falls into two categories; monarchy or a republic. A monarchy is a form of government that is always headed by a…show more content…\r\n",
    "King Fahad has complete control over it's citizens in all aspects pertaining to their country. Laws, punishments, and regulations are in the hands of King Fahad. \r\n",
    "If the government of a country does not fall into any of these categories, it is a republic. A republic is defined in Webster's Desk Dictionary of the English Language as any government in which the supreme power rests in the body of citizens entitled to vote and is exercised by representatives chosen directly or indirectly by them. There are three types of republics; dictatorship, oligarchy, or democracy. \r\n",
    "\"\"\"\r\n",
    "bow_vector_para = dictionary.doc2bow(preprocess(paragraph1))\r\n",
    "for index, score in sorted(lda_model[bow_vector_para], key= lambda tup: -1*tup[1]):\r\n",
    "    print(\"\\nScore: {}\\t \\nTopic: {}\".format(score, lda_model.print_topic(index, 7)))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Score: 0.21826614439487457\t \n",
      "Topic: 0.034*\"govern\" + 0.028*\"time\" + 0.026*\"road\" + 0.022*\"start\" + 0.016*\"pradesh\" + 0.015*\"return\" + 0.011*\"khan\"\n",
      "\n",
      "Score: 0.14241258800029755\t \n",
      "Topic: 0.028*\"bihar\" + 0.021*\"lakh\" + 0.018*\"bengaluru\" + 0.013*\"hold\" + 0.012*\"seiz\" + 0.011*\"celebr\" + 0.011*\"girl\"\n",
      "\n",
      "Score: 0.1255302131175995\t \n",
      "Topic: 0.038*\"say\" + 0.020*\"tamil\" + 0.019*\"farmer\" + 0.019*\"water\" + 0.019*\"lockdown\" + 0.018*\"nadu\" + 0.018*\"high\"\n",
      "\n",
      "Score: 0.11843184381723404\t \n",
      "Topic: 0.037*\"covid\" + 0.025*\"home\" + 0.025*\"hospit\" + 0.024*\"pune\" + 0.021*\"patient\" + 0.021*\"student\" + 0.015*\"onlin\"\n",
      "\n",
      "Score: 0.11246328800916672\t \n",
      "Topic: 0.021*\"polic\" + 0.018*\"bodi\" + 0.018*\"congress\" + 0.017*\"poll\" + 0.015*\"meet\" + 0.014*\"karnataka\" + 0.013*\"elect\"\n",
      "\n",
      "Score: 0.10346248000860214\t \n",
      "Topic: 0.053*\"year\" + 0.027*\"woman\" + 0.027*\"kill\" + 0.022*\"book\" + 0.021*\"mumbai\" + 0.016*\"die\" + 0.015*\"death\"\n",
      "\n",
      "Score: 0.06489361822605133\t \n",
      "Topic: 0.050*\"case\" + 0.030*\"covid\" + 0.028*\"cop\" + 0.025*\"arrest\" + 0.021*\"hold\" + 0.018*\"posit\" + 0.018*\"telangana\"\n",
      "\n",
      "Score: 0.04396703839302063\t \n",
      "Topic: 0.022*\"maharashtra\" + 0.022*\"death\" + 0.018*\"worker\" + 0.018*\"get\" + 0.017*\"gujarat\" + 0.016*\"school\" + 0.016*\"famili\"\n",
      "\n",
      "Score: 0.03689298778772354\t \n",
      "Topic: 0.026*\"rajasthan\" + 0.025*\"crore\" + 0.023*\"plan\" + 0.021*\"state\" + 0.021*\"help\" + 0.015*\"post\" + 0.014*\"near\"\n",
      "\n",
      "Score: 0.03367979824542999\t \n",
      "Topic: 0.027*\"india\" + 0.022*\"kolkata\" + 0.022*\"day\" + 0.020*\"hyderabad\" + 0.016*\"open\" + 0.015*\"test\" + 0.015*\"covid\"\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Results\r\n",
    "\r\n",
    "We can clearly see that even newspaper headline fed model can distinguish a text about government correctly. Better data can help model work more precise."
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.7.3",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.3 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}